{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e074dc",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/dusk/64/000000/artificial-intelligence.png\" style=\"height:50px;display:inline\"> EE 046202 - Technion - Unsupervised Learning & Data Analysis\n",
    "---\n",
    "\n",
    "#### <a href=\"https://lioritan.github.io\">Lior Friedman</a>\n",
    "\n",
    "## Tutorial 10 - Contrastive Learning Continues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f066e",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "---\n",
    "* [Bootstrap Your Own Latent (BYOL)](#-Bootstrap-Your-Own-Latent-(BYOL))\n",
    "* [Barlow Twins](#-Barlow-Twins)\n",
    "* [Lightly - implementing contrastive learning](#-Lightly---implementing-contrastive-learning)\n",
    "* [Recommended Videos](#-Recommended-Videos)\n",
    "* [Credits](#-Credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d079fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the tutorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0eda58",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/paper.png\" style=\"height:50px;display:inline\">  Reminder: Contrastive learning\n",
    "---\n",
    "* Similar things should be close, giving low loss, and dissimilar things should be far.\n",
    "* Use augmentations to find positive samples (similar things).\n",
    "* <img src=\"./assets/selfsup_contrast_augs.png\" style=\"height:200px;\">\n",
    "* Contrastive loss: collect a batch of $N$ samples and use $N-1$ as negative samples each time.\n",
    "* <img src=\"./assets/selfsup_infonce_loss.png\" style=\"height:100px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec53de",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/mountain.png\" style=\"height:50px;display:inline\"> Bootstrap Your Own Latent (BYOL)\n",
    "---\n",
    "* <a href=\"https://arxiv.org/abs/2006.07733\">Bootstrap Your Own Latent (BYOL)</a> creates two views of the data and tries to predict one from the other.\n",
    "* Unlike previous contrastive methods **there are no negative samples**.\n",
    "* Create two augmented views of a sample $x$, $t(x),t'(x)$, feed them to two neural networks and predict one from the other.\n",
    "* Each network has an encoder $f_\\theta$, a projector $g_\\theta$ and a predictor $q_\\theta$.\n",
    "<img src=\"./assets/selfsup_byol.png\" style=\"height:300px;\">\n",
    "1. Sample $t,t'\\sim \\tau$, get latent variables $z=g_\\theta(f_\\theta(t(x))),\\quad z_\\xi=g_\\xi(f_\\xi(t'(x)))$.\n",
    "2. Online network produces prediction $q_\\theta(z)$.\n",
    "3. Normalize $q_\\theta(z),z_\\xi$ ($L_2$-norm), $\\quad\\mathcal{L}_{BYOL}=\\mathrm{MSE}(q_\\theta(z),z_\\xi)$.\n",
    "4. Update online network with SGD, update target network via polyak averaging: $\\xi\\leftarrow\\alpha \\xi+(1-\\alpha)\\theta$.\n",
    "\n",
    "* **The MSE loss does not require negative samples**.\n",
    "* There is an *implicit* contrastive loss, by using **Batch Normalization** in the encoder and projection.\n",
    "* Without this batch normalization, BYOL fails catastrophically.\n",
    "* Why?\n",
    "    * One purpose of negative examples in a contrastive loss function is to prevent mode collapse (i.e. what if you use all-zeros representation for every data point?).\n",
    "    * BYOL has no negative samples, so we need some implict dependency on negative samples.\n",
    "    * This is exactly what batch normalization does, no matter how similar a batch of inputs are, the values are re-distributed according to the learned mean and standard deviation (and scaling-shifting).\n",
    "    * Mode collapse is prevented because all samples in the mini-batch **cannot take on the same value after batch normalization**.\n",
    "* In other words, BYOL learns by asking **“how is this image different from the average image?“**, whereas contrastive methods ask **“what distinguishes these two specific images from each other?”**\n",
    "<img src=\"./assets/selfsup_compare.png\" style=\"height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08839a63",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/yin-yang.png\" style=\"height:50px;display:inline\"> Barlow Twins\n",
    "---\n",
    "* <a href=\"https://arxiv.org/abs/2103.03230\">Barlow Twins</a> does something similar to CCA (canonical-correlation analysis).\n",
    "* Feed two distorted versions of the sample into the *same* network to extract features and learn to make the cross-correlation matrix between these two groups of output features **close to the identity matrix**. \n",
    "* In other words, the goal is to keep the representations of different versions of one sample similar, while minimizing the *redundancy* between these vectors (the idea comes from neuroscience).\n",
    "<img src=\"./assets/selfsup_barlow.png\" style=\"height:300px;\">\n",
    "1. Sample a batch of size, $N$, for each sample apply random augmentations $t,t'$ and encode: $z^A=f_\\theta(t(x)),z^B=f_\\theta(t'(x))$.\n",
    "2. Calculate the cross-correlation matrix $\\mathcal{C}$. \n",
    "    * $\\mathcal{C}$ is a square matrix with the size same as the feature network’s output dimensionality. \n",
    "    * Each entry in the matrix $\\mathcal{C}_{i,j}$ is the cosine similarity between the output vectors dimension at index $i,j$\n",
    "    * $$\\mathcal{C}_{i,j}=\\frac{\\sum_{b=1}^{N}z^A_{i,b}z^b_{j,b}}{\\sqrt{\\sum_b(z^A_{i,b})^2}\\sqrt{\\sum_b(z^B_{i,b})^2}}$$\n",
    "    * $\\mathcal{C}_{i,j}$ is between -1 (i.e. perfect anti-correlation) and 1 (i.e. perfect correlation).\n",
    "3. $$\\mathcal{L}_\\mathrm{BT} = \\underbrace{\\sum_i (1-\\mathcal{C}_{ii})^2}_\\mathrm{invariance-term} + \\lambda \\underbrace{\\sum_i\\sum_{i\\neq j} \\mathcal{C}_{ij}^2}_\\mathrm{redundancy-reduction-term}$$\n",
    "\n",
    "Notes:\n",
    "* *Explicitly reduces redundancy*, so no need for batch normalization to avoid mode collapse in the representation.\n",
    "* Pretty robust to batch size, but sensitive to the choice of augmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ade27e",
   "metadata": {},
   "source": [
    "### <img src=\"./assets/selfsup_lightly.png\" style=\"height:50px;display:inline\"> Lightly - implementing contrastive learning\n",
    "---\n",
    "* Lightly SSL is a computer vision framework for self-supervised learning. \n",
    "* Contains Pytorch-based implementations for many popular models, including everything we talked about.\n",
    "* **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c42e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ca245c",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/video-playlist.png\" style=\"height:50px;display:inline\"> Recommended Videos\n",
    "---\n",
    "#### <img src=\"https://img.icons8.com/cute-clipart/64/000000/warning-shield.png\" style=\"height:30px;display:inline\"> Warning!\n",
    "* These videos do not replace the lectures and tutorials.\n",
    "* Please use these to get a better understanding of the material, and not as an alternative to the written material.\n",
    "\n",
    "#### Video By Subject\n",
    "\n",
    "* BYOL - <a href=\"https://www.youtube.com/watch?v=YPfUiOMYOEE\"> BYOL: Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning </a>\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94976441",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "---\n",
    "* <a href=\"https://github.com/taldatech/ee046211-deep-learning/blob/main/ee046211_tutorial_09_self_supervised_representation_learning.ipynb\"> ee045211 - Deep Learning </a> @ Technion\n",
    "* <a href=\"https://lilianweng.github.io/posts/2021-05-31-contrastive/\"> Weng, Lilian. (May 2021). Contrastive representation learning. Lil’Log </a>\n",
    "* <a href=\"https://imbue.com/research/2020-08-24-understanding-self-supervised-contrastive-learning/\"> Understanding self-supervised and contrastive learning with BYOL </a>\n",
    "* A Cookbook of Self-Supervised Learning, Balestriero et al. 2023\n",
    "* <a href=\"https://paperswithcode.com/method/byol\">Bootstrap Your Own Latent (BYOL)</a>\n",
    "* <a href=\"https://paperswithcode.com/method/barlow-twins\">Barlow Twins</a>\n",
    "* <a href=\"https://github.com/lightly-ai/lightly\">Lightly SSL</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
